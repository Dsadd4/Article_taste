import os
import sys
import time
import json
import schedule
import requests
from bs4 import BeautifulSoup
from PyQt5.QtWidgets import (QApplication, QMainWindow, QLabel, QVBoxLayout, QPushButton, QWidget, QScrollArea)
from pystray import Icon, MenuItem, Menu
from PIL import Image
import win32com.client
import os
import json
import requests
from bs4 import BeautifulSoup
from datetime import datetime
import re

# === CONFIGURATION ===
CONFIG_FILE = 'config.json'
CACHE_FILE = 'cache.json'

# Load configuration
if os.path.exists(CONFIG_FILE):
    with open(CONFIG_FILE, 'r') as f:
        CONFIG = json.load(f)
else:
    CONFIG = {"keywords": []}

# === MODULES ===


def fetch_arxiv():
    try:
        if is_cached('arxiv'):
            return load_cache('arxiv')

        url = "https://arxiv.org/list/cs.AI/recent"
        response = requests.get(url)
        soup = BeautifulSoup(response.text, 'html.parser')
        papers = []
        # æ‰¾åˆ°æ‰€æœ‰ dt æ ‡ç­¾
        articles = soup.find_all('dt')
        for article in articles:
            # æå–æ–‡ç« é“¾æ¥
            link = f"https://arxiv.org{article.find('a', title='Abstract')['href']}"
            
            # ä¸¾ä¾‹ï¼Œè¿™æ˜¯pdfçš„åœ°å€ https://arxiv.org/pdf/2503.10542
            #è¿™æ˜¯å¤§çº²é¡µé¢çš„åœ°å€ https://arxiv.org/abs/2503.10542
            # æ‰¾åˆ°å¯¹åº”çš„ dd æ ‡ç­¾
            details = article.find_next_sibling('dd')
            
            if details:
                # æå–æ ‡é¢˜
                title = details.find('div', class_='list-title').get_text(strip=True).replace('Title:', '').strip()
                
                # æå–ä½œè€…
                authors = [a.get_text(strip=True) for a in details.find('div', class_='list-authors').find_all('a')]
                
                # æå–ä¸»é¢˜
                subjects = details.find('div', class_='list-subjects').get_text(strip=True).replace('Subjects:', '').strip()
                papers.append((title,link))
        #debug
        # print(papers)
        
        save_cache('arxiv', papers)
        return papers
    except Exception as e:
        return [(f"Error fetching ArXiv: {str(e)}", "")]
    



import requests
from bs4 import BeautifulSoup

#=== å¤„ç†natureç³»åˆ—æœŸåˆŠ ===
# æ˜ å°„ journal_name åˆ°æœŸåˆŠç¼©å†™
JOURNAL_MAPPING = {
    'nature_biotechnology': 'nbt',
    'nature_methods': 'nmeth',
    'nature_machine_intelligence': 'natmachintell',
    'nature': 'nature',
    'nature_computer_science': 'natcomputsci',
    'nature_communications': 'ncomms'
}




import concurrent.futures
import requests
from bs4 import BeautifulSoup


# æ¯æ‰¹æŠ“å– 10 é¡µï¼Œæ¯æ¬¡å¯åŠ¨ 10 ä¸ªçº¿ç¨‹
BATCH_SIZE = 10
MAX_THREADS = 10
MAX_PAGES = 100  # æœ€å¤šæŠ“100é¡µï¼Œé˜²æ­¢æ— é™çˆ¬å–

def fetch_page(journal_name, page_number):
    try:
        journal_abbr = JOURNAL_MAPPING[journal_name] 
        url = f"https://www.nature.com/{journal_abbr}/articles?searchType=journalSearch&sort=PubDate&year=2025&page={page_number}"
        response = requests.get(url, timeout=10)
        if response.status_code != 200:
            return []

        soup = BeautifulSoup(response.text, 'html.parser')
        articles = soup.find_all('li', class_='app-article-list-row__item')
        if not articles:
            return []

        papers = []
        for article in articles:
            link_tag = article.find('a', class_='c-card__link u-link-inherit')
            if link_tag and 'href' in link_tag.attrs:
                link = f"https://www.nature.com{link_tag['href']}"
            else:
                continue

            title = link_tag.get_text(strip=True)

            # æ‘˜è¦
            summary = article.find('div', class_='c-card__summary')
            if summary:
                p_tag = summary.find('p')
                summary_text = p_tag.get_text(strip=True) if p_tag else "No summary available"
            else:
                summary_text = "No summary available"

            # å‘å¸ƒæ—¥æœŸ
            date_published = article.find('time', class_="c-meta__item c-meta__item--block-at-lg")
            date_published = date_published.get_text(strip=True) if date_published else "No date available"

            papers.append((title, link, summary_text, date_published))

        return papers

    except Exception as e:
        print(f"Error fetching page {page_number}: {e}")
        return []


def fetch_nature_series(journal_name):
    try:
        if is_cached(journal_name):
            return load_cache(journal_name)

        papers = []
        page_number = 1

        while True:
            print(f"ğŸš€ å¼€å§‹æŠ“å–ç¬¬ {page_number} é¡µåˆ°ç¬¬ {page_number + BATCH_SIZE - 1} é¡µ")

            batch_results = []
            stop_flag = False

            # ä½¿ç”¨ ThreadPoolExecutor è¿›è¡Œå¹¶è¡ŒæŠ“å–
            with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:
                future_to_page = {
                    executor.submit(fetch_page, journal_name, page): page
                    for page in range(page_number, page_number + BATCH_SIZE)
                }
                for future in concurrent.futures.as_completed(future_to_page):
                    page = future_to_page[future]
                    try:
                        result = future.result()
                        if not result:
                            print(f"âš ï¸ ç¬¬ {page} é¡µä¸ºç©ºï¼Œå¯èƒ½æ˜¯æœ«é¡µï¼Œå‡†å¤‡åœæ­¢æŠ“å–ã€‚")
                            stop_flag = True
                        else:
                            batch_results.extend(result)
                    except Exception as e:
                        print(f"âš ï¸ æŠ“å–ç¬¬ {page} é¡µå¤±è´¥: {e}")

            # åˆå¹¶å½“å‰æ‰¹æ¬¡ç»“æœ
            papers.extend(batch_results)

            if stop_flag or page_number + BATCH_SIZE > MAX_PAGES:
                print("âœ… æŠ“å–å®Œæˆï¼")
                break

            # æ›´æ–°ä¸‹ä¸€æ‰¹æŠ“å–çš„èµ·ç‚¹
            page_number += BATCH_SIZE

        # ä¿å­˜ç»“æœï¼ˆç¼“å­˜ï¼‰
        save_cache(journal_name, papers)
        return papers

    except Exception as e:
        print(f"âŒ Error fetching {journal_name}: {e}")
        return [(f"Error fetching {journal_name}: {str(e)}", "", "", "")]





def sanitize_filename(filename):
    # å»é™¤ä¸åˆæ³•çš„æ–‡ä»¶åå­—ç¬¦
    return re.sub(r'[\/:*?"<>|]', '', filename)

def create_download_dir():
    today = datetime.today().strftime('%Y-%m-%d')
    download_path = os.path.join(os.getcwd(), 'download', today)
    if not os.path.exists(download_path):
        os.makedirs(download_path, exist_ok=True)
    return download_path

def download_pdf(title, link):
    try:
        download_path = create_download_dir()
        pdf_link = link.replace('/abs/', '/pdf/')

        #debug
        print(f"we now try to download{pdf_link } ")

        response = requests.get(pdf_link)
        if response.status_code == 200:
            sanitized_title = sanitize_filename(title)
            filename = os.path.join(download_path, f"{sanitized_title}.pdf")
            with open(filename, 'wb') as f:
                f.write(response.content)
            print(f"âœ… Downloaded: {filename}")
        else:
            print(f"âŒ Failed to download: {pdf_link} (Status Code: {response.status_code})")
    except Exception as e:
        print(f"âŒ Error downloading {link}: {str(e)}")



def fetch_huggingface():
    try:
        if is_cached('huggingface'):
            return load_cache('huggingface')
        url = "https://huggingface.co/blog"
        response = requests.get(url)
        soup = BeautifulSoup(response.text, 'html.parser')
        papers = []
        for entry in soup.find_all('h2'):
            title = entry.get_text(strip=True)
            link = entry.find_next('a')['href'] if entry.find_next('a') else ""
            papers.append((title, link))
        save_cache('huggingface', papers)
        return papers
        
    except Exception as e:
        return [(f"Error fetching HuggingFace: {str(e)}", "")]



# === CACHE HANDLING ===
def save_cache(source, data):
    cache = load_all_cache()
    cache[source] = {"data": data, "timestamp": time.strftime('%Y-%m-%d')}
    with open(CACHE_FILE, 'w') as f:
        json.dump(cache, f)

def load_cache(source):
    cache = load_all_cache()
    return cache.get(source, {}).get("data", [])

def load_all_cache():
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, 'r') as f:
            return json.load(f)
    return {}

def is_cached(source):
    cache = load_all_cache()
    cached_date = cache.get(source, {}).get("timestamp", "")
    return cached_date == time.strftime('%Y-%m-%d')


from PyQt5.QtCore import QThreadPool
from PyQt5.QtCore import Qt

import os
import json
from PyQt5.QtWidgets import (
    QApplication, QMainWindow, QVBoxLayout, QPushButton, QLabel, QScrollArea, QWidget, QMenu, QAction, QMessageBox
)
from PyQt5.QtCore import Qt, QThread, pyqtSignal, QPoint
from PyQt5.QtGui import QCursor
from PyQt5.QtWidgets import QMenu, QAction, QVBoxLayout, QWidget, QPushButton, QTextBrowser, QMainWindow
from PyQt5.QtCore import Qt


FAVORITES_FILE = 'favorites.json'
# === GUI ===
class MainWindow(QMainWindow):
    def __init__(self):
        super().__init__()
        self.setWindowTitle("ç§‘ç ”ä¿¡æ¯æŠ“å–åŠ©æ‰‹")
        self.setGeometry(100, 100, 1200, 1200)
        self.favorites = self.load_favorites()
        layout = QVBoxLayout()

        # Buttons

        # åˆ›å»ºarxivä¸å…³é”®ä¿¡æ¯ç½‘ç«™
        self.arxiv_button = QPushButton("ArXiv")
        self.arxiv_button.clicked.connect(lambda: self.start_fetch_arxiv())
        layout.addWidget(self.arxiv_button)

        self.huggingface_button = QPushButton("HuggingFace")
        self.huggingface_button.clicked.connect(lambda: self.start_fetch_huggingface())
        layout.addWidget(self.huggingface_button)


        # åˆ›å»ºnatureç³»åˆ—æŒ‰é’®
        self.nbt_button = QPushButton("Nature Biotechnology")
        self.nbt_button.clicked.connect(lambda: self.start_fetch('nature_biotechnology'))
        layout.addWidget(self.nbt_button)

        self.nmeth_button = QPushButton("Nature Methods")
        self.nmeth_button.clicked.connect(lambda: self.start_fetch('nature_methods'))
        layout.addWidget(self.nmeth_button)

        self.nmachintell_button = QPushButton("Nature Machine Intelligence")
        self.nmachintell_button.clicked.connect(lambda: self.start_fetch('nature_machine_intelligence'))
        layout.addWidget(self.nmachintell_button)

        self.nature_button = QPushButton("Nature")
        self.nature_button.clicked.connect(lambda: self.start_fetch('nature'))
        layout.addWidget(self.nature_button)

        self.ncomputersci_button = QPushButton("Nature Computer Science")
        self.ncomputersci_button.clicked.connect(lambda: self.start_fetch('nature_computer_science'))
        layout.addWidget(self.ncomputersci_button)

        self.ncomms_button = QPushButton("Nature Communications")
        self.ncomms_button.clicked.connect(lambda: self.start_fetch('nature_communications'))
        layout.addWidget(self.ncomms_button)


        self.download_button = QPushButton("Download_papers_withhighlight")
        self.download_button.clicked.connect(self.download)
        layout.addWidget(self.download_button)


        self.update_button = QPushButton("æ›´æ–°")
        self.update_button.clicked.connect(self.clear_cache)
        layout.addWidget(self.update_button)


        # â¤ï¸ æ”¶è—å¤¹æŒ‰é’®
        self.favorites_button = QPushButton("ğŸ“ æŸ¥çœ‹æ”¶è—å¤¹")
        self.favorites_button.clicked.connect(self.show_favorites)
        layout.addWidget(self.favorites_button)


        # # Scrollable area for displaying results
        # self.result_area = QScrollArea()
        self.result_label = QLabel("ç‚¹å‡»æŒ‰é’®è·å–æœ€æ–°ä¿¡æ¯")
        self.result_label.setStyleSheet("font-size: 16px;")
        self.result_label.setTextFormat(Qt.RichText)  # å…è®¸è§£æ HTML æ ¼å¼
        self.result_label.setOpenExternalLinks(True)  # å…è®¸ç‚¹å‡»å¤–éƒ¨é“¾æ¥
        self.result_label.setTextInteractionFlags(Qt.TextBrowserInteraction)  # å…è®¸ç‚¹å‡»å’Œé€‰æ‹©æ–‡æœ¬
        self.result_label.setContextMenuPolicy(Qt.CustomContextMenu)
        self.result_label.customContextMenuRequested.connect(self.show_context_menu)

        self.result_label.setContextMenuPolicy(Qt.CustomContextMenu)
        self.result_label.customContextMenuRequested.connect(self.show_context_menu)

        # ç»“æœå±•ç¤ºåŒºåŸŸ
        self.result_area = QTextBrowser()
        self.result_area.setOpenExternalLinks(True)
        self.result_area.setTextInteractionFlags(Qt.TextBrowserInteraction)
        self.result_area.setContextMenuPolicy(Qt.CustomContextMenu)
        self.result_area.customContextMenuRequested.connect(self.show_context_menu)


        self.result_area.setWidget(self.result_label)
        self.result_area.setWidgetResizable(True)
        layout.addWidget(self.result_area)

        container = QWidget()
        container.setLayout(layout)
        self.setCentralWidget(container)

        # # å‡è®¾ä½ æœ‰ä¸€ä¸ªCONFIGå­—å…¸åŒ…å«æœŸåˆŠå’Œå…³é”®è¯ç­‰é…ç½®
        # self.CONFIG = {
        #     "arxiv": {"fields": 2, "keywords": ["AI", "Machine Learning"]},  # arxivåªæŠ“å–2é¡¹
        #     "nbt": {"fields": 4, "keywords": ["Gene", "DNA", "Lipids"]},     # nbtæŠ“å–4é¡¹
        #     # å…¶ä»–æœŸåˆŠçš„é…ç½®
        # }

        # âœ… å³é”®èœå•ï¼ˆç”¨äºæ·»åŠ åˆ°æ”¶è—å¤¹ï¼‰
    def show_context_menu(self, pos):
        menu = QMenu(self)

        add_fav_action = QAction("æ·»åŠ åˆ°æ”¶è—å¤¹", self)
        add_fav_action.triggered.connect(self.add_to_favorites)
        menu.addAction(add_fav_action)

        cursor_pos = self.result_label.mapFromGlobal(pos)  # è·å–é¼ æ ‡åœ¨QLabelä¸­çš„ä½ç½®
        link = self.get_link_under_cursor(cursor_pos)
        title = self.get_title_under_cursor(cursor_pos)

        if link and title:
            self.current_link = link
            self.current_title = title
            menu.exec_(self.result_label.mapToGlobal(pos))
        else:
            self.current_link = None
            self.current_title = None

    def get_link_under_cursor(self, cursor_pos):
        text = self.result_label.text()
        pattern = r'href="(.*?)"'  # åŒ¹é…è¶…é“¾æ¥
        matches = re.findall(pattern, text)

        # é€ä¸€æ£€æŸ¥é¼ æ ‡ä½ç½®å¯¹åº”çš„é“¾æ¥
        for match in matches:
            # å¦‚æœéœ€è¦æ›´å¤æ‚çš„å®šä½ï¼Œå¯ä»¥æ ¹æ®cursor_posè®¡ç®—
            # ç›®å‰æˆ‘ä»¬å‡è®¾ç¬¬ä¸€ä¸ªé“¾æ¥ä¸ºåŒ¹é…çš„é“¾æ¥
            return match
        return None

    def get_title_under_cursor(self, cursor_pos):
        text = self.result_label.text()
        pattern = r'>(.*?)</a>'  # åŒ¹é…é“¾æ¥ä¸­çš„æ ‡é¢˜
        matches = re.findall(pattern, text)

        # é€ä¸€æ£€æŸ¥é¼ æ ‡ä½ç½®å¯¹åº”çš„æ ‡é¢˜
        for match in matches:
            # å¦‚æœéœ€è¦æ›´å¤æ‚çš„å®šä½ï¼Œå¯ä»¥æ ¹æ®cursor_posè®¡ç®—
            # ç›®å‰æˆ‘ä»¬å‡è®¾ç¬¬ä¸€ä¸ªæ ‡é¢˜ä¸ºåŒ¹é…çš„æ ‡é¢˜
            return match
        return None

    def add_to_favorites(self):
        if self.current_link and self.current_title:
            # å­˜å‚¨åˆ°æ”¶è—å¤¹ä¸­
            if (self.current_title, self.current_link) not in self.favorites:
                self.favorites.append((self.current_title, self.current_link))
                self.save_favorites()
                print(f"âœ… å·²æ”¶è—: {self.current_title}")
            else:
                print(f"âš ï¸ å·²ç»æ”¶è—è¿‡äº†: {self.current_title}")
                
            
        # âœ… æ˜¾ç¤ºæ”¶è—å¤¹å†…å®¹
    def show_favorites(self):
        if not self.favorites:
            self.result_label.setText("â¤ï¸ æ”¶è—å¤¹ä¸ºç©º")
        else:
            favorites_html = []
            for title, link in self.favorites:
                favorites_html.append(f'<a href="{link}" target="_blank" style="color:blue;font-size:16px;">{title}</a>')
            self.result_label.setText("<br><br>".join(favorites_html))

    # âœ… åŠ è½½æ”¶è—å¤¹
    def load_favorites(self):
        if os.path.exists(FAVORITES_FILE):
            with open(FAVORITES_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        return []

    # âœ… ä¿å­˜æ”¶è—å¤¹
    def save_favorites(self):
        with open(FAVORITES_FILE, 'w', encoding='utf-8') as f:
            json.dump(self.favorites, f, indent=4, ensure_ascii=False)


    def show_results(self, results):
        highlighted_results = []
        
        if(len(results[0])==2):
            for title, link in results:
                title = insert_changeline(title)
                if any(keyword.lower() in title.lower() for keyword in CONFIG["keywords"]):
                    result_html = f'<b><a href="{link}" target="_blank" style="color:red;font-size:20px;">{title}</a></b>'
                else:
                    result_html = f'<a href="{link}" target="_blank" style="color:black;font-size:16px;">{title}</a>'
                
                highlighted_results.append(result_html)
        elif(len(results[0])==4):
            for title, link,__,___ in results:
                title = insert_changeline(title)
                if any(keyword.lower() in title.lower() for keyword in CONFIG["keywords"]):
                    result_html = f'<b><a href="{link}" target="_blank" style="color:red;font-size:20px;">{title}</a></b>'
                else:
                    result_html = f'<a href="{link}" target="_blank" style="color:black;font-size:16px;">{title}</a>'
                
                highlighted_results.append(result_html)

        self.result_label.setText("<br><br>".join(highlighted_results))

    

    def clear_cache(self):
        if os.path.exists(CACHE_FILE):
            os.remove(CACHE_FILE)
        self.result_label.setText("ç¼“å­˜å·²æ¸…é™¤ï¼")



    def download(self):
        self.result_label.setText("begin...")
        papers = fetch_arxiv()
        keywords = [kw.lower() for kw in CONFIG["keywords"]]
        
        matched_papers = [(title, link) for title, link in papers if any(kw in title.lower() for kw in keywords)]
        
        print(f"ğŸ” Found {len(matched_papers)} matching papers")
        
        # ä¸ºæ¯ç¯‡è®ºæ–‡å¯åŠ¨ä¸€ä¸ªä¸‹è½½çº¿ç¨‹
        self.threads = []  # ä¿å­˜æ‰€æœ‰çš„ä¸‹è½½çº¿ç¨‹ï¼Œä»¥ä¾¿ç®¡ç†å®ƒä»¬
        for title, link in matched_papers:
            download_thread = DownloadThread(title, link)
            download_thread.download_done.connect(self.on_download_done)
            download_thread.start()
            self.threads.append(download_thread)

    def on_download_done(self, message):
        # æ¯å½“ä¸€ä¸ªä¸‹è½½å®Œæˆåè°ƒç”¨è¿™ä¸ªæ–¹æ³•
        print(message)  # æ‰“å°ä¸‹è½½å®Œæˆçš„ä¿¡æ¯ï¼Œå¯ä»¥æ›´æ–° UI æ¥æ˜¾ç¤º

        # è¿™é‡Œå¯ä»¥æ›´æ–°ç•Œé¢ï¼Œæ˜¾ç¤ºä¸‹è½½çš„è¿›åº¦æˆ–å®Œæˆæƒ…å†µ
        self.result_label.setText(message)

    def closeEvent(self, event):
        """ç¡®ä¿åœ¨åº”ç”¨é€€å‡ºæ—¶ï¼Œæ‰€æœ‰çº¿ç¨‹è¢«æ­£ç¡®ç»ˆæ­¢"""
        for thread in self.threads:
            thread.terminate()
            thread.wait()
        self.save_favorites()
        
        event.accept()
    

    def start_fetch(self, journal_name):
        self.thread = FetchNatureThread(journal_name)  
        self.thread.result_signal.connect(self.show_results)  # ç»‘å®šä¿¡å·åˆ°å›è°ƒå‡½æ•°
        self.thread.start()  # å¯åŠ¨çº¿ç¨‹

    def start_fetch_arxiv(self):
        self.thread = FetcharxivThread()  
        self.thread.result_signal.connect(self.show_results)  # ç»‘å®šä¿¡å·åˆ°å›è°ƒå‡½æ•°
        self.thread.start()  # å¯åŠ¨çº¿ç¨‹

    def start_fetch_huggingface(self):
        self.thread = FethuggingfaceThread()  
        self.thread.result_signal.connect(self.show_results)  # ç»‘å®šä¿¡å·åˆ°å›è°ƒå‡½æ•°
        self.thread.start()  # å¯åŠ¨çº¿ç¨‹

# === utils ====
def insert_changeline(title):
    setlens = 88
    for i in range(setlens,len(title),setlens):
        title= title[:i]+'<br>'+title[i:]
    return title

from PyQt5.QtCore import QThread, pyqtSignal

class DownloadThread(QThread):
    # å®šä¹‰ä¸€ä¸ªä¿¡å·ï¼Œç”¨äºé€šçŸ¥ä¸‹è½½å®Œæˆ
    download_done = pyqtSignal(str)  # ä¼ é€’æ–‡ä»¶åæˆ–å…¶ä»–ä¿¡æ¯

    def __init__(self, title, link, parent=None):
        super().__init__(parent)
        self.title = title
        self.link = link

    def run(self):
        try:
            # æ‰§è¡Œä¸‹è½½ä»»åŠ¡
            download_pdf(self.title, self.link)
            # ä¸‹è½½å®Œæˆåå‘å‡ºä¿¡å·
            self.download_done.emit(f"{self.title} ä¸‹è½½å®Œæˆ")
        except Exception as e:
            self.download_done.emit(f"ä¸‹è½½å¤±è´¥: {self.title}ï¼Œ é”™è¯¯: {str(e)}")

    def stop(self):
        """å¦‚æœéœ€è¦åœæ­¢çº¿ç¨‹ï¼Œæ·»åŠ ä¸€ä¸ªåœæ­¢æ–¹æ³•"""
        self.terminate()
        self.wait()




from PyQt5.QtCore import QThread, pyqtSignal
from PyQt5.QtWidgets import QApplication, QPushButton, QVBoxLayout, QWidget

class FetchNatureThread(QThread):
    result_signal = pyqtSignal(list)  # å®šä¹‰ä¿¡å·ï¼Œä¼ é€’æŠ“å–ç»“æœ

    def __init__(self, journal_name):
        super().__init__()
        self.journal_name = journal_name

    def run(self):
        try:
            # è°ƒç”¨ fetch_nature_series æŠ“å–æ•°æ®
            result = fetch_nature_series(self.journal_name)
            self.result_signal.emit(result)  # å‘é€ä¿¡å·ï¼Œå°†ç»“æœä¼ å›ä¸»çº¿ç¨‹
        except Exception as e:
            self.result_signal.emit([(f"Error fetching {self.journal_name}: {str(e)}", "", "", "")])


class FetcharxivThread(QThread):
    result_signal = pyqtSignal(list)  # å®šä¹‰ä¿¡å·ï¼Œä¼ é€’æŠ“å–ç»“æœ

    def __init__(self):
        super().__init__()

    def run(self):
        try:
            # è°ƒç”¨ fetch_nature_series æŠ“å–æ•°æ®
            result = fetch_arxiv()
            self.result_signal.emit(result)  # å‘é€ä¿¡å·ï¼Œå°†ç»“æœä¼ å›ä¸»çº¿ç¨‹
        except Exception as e:
            self.result_signal.emit([(f"Error fetching {self.journal_name}: {str(e)}", "", "", "")])

class FethuggingfaceThread(QThread):
    result_signal = pyqtSignal(list)  # å®šä¹‰ä¿¡å·ï¼Œä¼ é€’æŠ“å–ç»“æœ

    def __init__(self):
        super().__init__()

    def run(self):
        try:
            # è°ƒç”¨ fetch_nature_series æŠ“å–æ•°æ®
            result = fetch_huggingface()
            self.result_signal.emit(result)  # å‘é€ä¿¡å·ï¼Œå°†ç»“æœä¼ å›ä¸»çº¿ç¨‹
        except Exception as e:
            self.result_signal.emit([(f"Error fetching {self.journal_name}: {str(e)}", "", "", "")])


# === SYSTEM TRAY ===

def setup(icon):
    icon.visible = True

def run_tray():
    icon = Icon("ç§‘ç ”åŠ©æ‰‹", Image.open("icon.png"), menu=Menu(
        MenuItem('æ˜¾ç¤º', lambda icon, item: print("æ˜¾ç¤ºçª—å£")),
        MenuItem('é€€å‡º', lambda icon, item: icon.stop())
    ))
    icon.run(setup)

# === SCHEDULER ===
def job():
    papers_arxiv = fetch_arxiv()
    papers_hf = fetch_huggingface()
    print("[Arxiv]:", papers_arxiv)
    print("[HuggingFace]:", papers_hf)

schedule.every().day.at("09:00").do(job)

def run_scheduler():
    while True:
        schedule.run_pending()
        time.sleep(1)

# === AUTO STARTUP ===
def create_shortcut():
    startup_folder = os.path.join(os.getenv('APPDATA'), 'Microsoft', 'Windows', 'Start Menu', 'Programs', 'Startup')
    shortcut_path = os.path.join(startup_folder, 'ç§‘ç ”åŠ©æ‰‹.lnk')

    shell = win32com.client.Dispatch("WScript.Shell")
    shortcut = shell.CreateShortcut(shortcut_path)
    shortcut.TargetPath = sys.executable
    shortcut.WorkingDirectory = os.getcwd()
    shortcut.Save()

# === MAIN ===
def main():
    create_shortcut()

    app = QApplication(sys.argv)
    window = MainWindow()
    window.show()

    import threading
    threading.Thread(target=run_scheduler, daemon=True).start()
    threading.Thread(target=run_tray, daemon=True).start()

    sys.exit(app.exec_())

if __name__ == "__main__":
    main()
